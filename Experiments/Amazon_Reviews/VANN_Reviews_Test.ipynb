{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available  (error: Unable to get the number of gpus available: invalid argument)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "from collections import OrderedDict\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "import pickle\n",
    "\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "sys.path.insert(0, \"/home/cwhuang/DVTL/Model/\")\n",
    "import nnet as nn\n",
    "import criteria\tas er\n",
    "import util\n",
    "import VANN\n",
    "\n",
    "import DataPackage as dp\n",
    "import AmazonReviewsFeaturePlot as fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2499: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of minibatch at one epoch: 20, batch size source : 80, target : 80 \n",
      " validation size, S:400, T:400, test size, S:4465, T:3586\n",
      "... building the model\n",
      "Encoder1_share is constructed with hidden layer number 0\n",
      "Encoder1_mu is constructed with hidden layer number 0\n",
      "Encoder1_sigma is constructed with hidden layer number 0\n",
      "Encoder3_pi is constructed with hidden layer number 0\n",
      "Encoder2_share is constructed with hidden layer number 0\n",
      "Encoder2_mu is constructed with hidden layer number 0\n",
      "Encoder2_sigma is constructed with hidden layer number 0\n",
      "Decoder1_share is constructed with hidden layer number 0\n",
      "Decoder1_mu is constructed with hidden layer number 0\n",
      "Decoder1_sigma is constructed with hidden layer number 0\n",
      "Decoder2_share is constructed with hidden layer number 0\n",
      "Decoder2_mu is constructed with hidden layer number 0\n",
      "Decoder2_sigma is constructed with hidden layer number 0\n",
      "DomainClassifier is constructed with hidden layer number 0\n",
      "Encoder1_share is constructed with hidden layer number 0\n",
      "Encoder1_mu is constructed with hidden layer number 0\n",
      "Encoder1_sigma is constructed with hidden layer number 0\n",
      "Encoder3_pi is constructed with hidden layer number 0\n",
      "Encoder2_share is constructed with hidden layer number 0\n",
      "Encoder2_mu is constructed with hidden layer number 0\n",
      "Encoder2_sigma is constructed with hidden layer number 0\n",
      "Decoder1_share is constructed with hidden layer number 0\n",
      "Decoder1_mu is constructed with hidden layer number 0\n",
      "Decoder1_sigma is constructed with hidden layer number 0\n",
      "Decoder2_share is constructed with hidden layer number 0\n",
      "Decoder2_mu is constructed with hidden layer number 0\n",
      "Decoder2_sigma is constructed with hidden layer number 0\n",
      "DomainClassifier is constructed with hidden layer number 0\n",
      "Encoder1_share is constructed with hidden layer number 0\n",
      "Encoder1_mu is constructed with hidden layer number 0\n",
      "Encoder1_sigma is constructed with hidden layer number 0\n",
      "Encoder3_pi is constructed with hidden layer number 0\n",
      "Encoder2_share is constructed with hidden layer number 0\n",
      "Encoder2_mu is constructed with hidden layer number 0\n",
      "Encoder2_sigma is constructed with hidden layer number 0\n",
      "Decoder1_share is constructed with hidden layer number 0\n",
      "Decoder1_mu is constructed with hidden layer number 0\n",
      "Decoder1_sigma is constructed with hidden layer number 0\n",
      "Decoder2_share is constructed with hidden layer number 0\n",
      "Decoder2_mu is constructed with hidden layer number 0\n",
      "Decoder2_sigma is constructed with hidden layer number 0\n",
      "DomainClassifier is constructed with hidden layer number 0\n",
      "... training\n",
      "Initial, test accuracy: source domain :49.496081 %, target domain 50.362521 %\n",
      "epoch 1, minibatch 20/20, training loss 2485.297547, validation loss 2501.318034 \n",
      "     epoch 1, minibatch 20/20, test accuracy of best model: source domain :49.294513 %, target domain 49.609593 %\n",
      "epoch 2, minibatch 20/20, training loss 2263.271543, validation loss 2301.984538 \n",
      "     epoch 2, minibatch 20/20, test accuracy of best model: source domain :59.350504 %, target domain 55.772448 %\n",
      "epoch 3, minibatch 20/20, training loss 2241.501745, validation loss 2298.388390 \n",
      "     epoch 3, minibatch 20/20, test accuracy of best model: source domain :68.129899 %, target domain 64.472950 %\n",
      "epoch 4, minibatch 20/20, training loss 2386.654944, validation loss 2427.458661 \n",
      "epoch 5, minibatch 20/20, training loss 2115.746004, validation loss 2223.339154 \n",
      "     epoch 5, minibatch 20/20, test accuracy of best model: source domain :77.110862 %, target domain 74.093698 %\n",
      "epoch 6, minibatch 20/20, training loss 2100.275083, validation loss 2253.733343 \n",
      "epoch 7, minibatch 20/20, training loss 2063.698121, validation loss 2253.077614 \n",
      "epoch 8, minibatch 20/20, training loss 2036.988859, validation loss 2279.252227 \n",
      "epoch 9, minibatch 20/20, training loss 2185.452650, validation loss 2578.823600 \n",
      "epoch 10, minibatch 20/20, training loss 2025.863865, validation loss 2363.020531 \n",
      "epoch 11, minibatch 20/20, training loss 2016.575730, validation loss 2355.587696 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8335a811a6e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mstruct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mcoef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoef\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[0mdescription\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m     )\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/cwhuang/DVLTL/DVLTL/VANN.pyc\u001b[0m in \u001b[0;36mVANN_training\u001b[1;34m(source_data, target_data, n_train_batches, n_epochs, k, struct, coef, description, process_display)\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;31m# first train domain classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m                 \u001b[0mtrain_DoC_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_index\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mn_train_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m             \u001b[0mminibatch_avg_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_latent_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminibatch_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''Model Construct'''\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    max_feature=2000\n",
    "    source_data, target_data = dp.datapackage(source='books', target='dvd', max_feature=max_feature, tfidf_setting='seperate')\n",
    "    \n",
    "    #source_data, target_data = DataDuplicate.DataDuplicate(source_data, target_data)   \n",
    "    \n",
    "    ########################################################################\n",
    "    ###                        Coefficient Initial                       ###\n",
    "    ########################################################################        \n",
    "\n",
    "    x_dim = max_feature\n",
    "    y_dim = 2    \n",
    "    d_dim = 2\n",
    "    z_dim = 50                #dimension of latent feature\n",
    "    a_dim = 50               #dimension of prior of latent feature    \n",
    "    h_zy_dim = 500             #dimension of hidden unit  \n",
    "    h_ay_dim = 100\n",
    "    h_y_dim = 30\n",
    "    learning_rate = 0.005\n",
    "    activation = T.nnet.sigmoid\n",
    "    \n",
    "    struct = VANN.VANN_struct()    \n",
    "    encoder_template = nn.NN_struct()\n",
    "\n",
    "    \n",
    "    struct.encoder1.share.layer_dim = [x_dim+d_dim, h_zy_dim]\n",
    "    struct.encoder1.share.activation = [activation]\n",
    "    struct.encoder1.share.learning_rate = [learning_rate, learning_rate]\n",
    "    struct.encoder1.share.decay = [1, 1]                \n",
    "\n",
    "    struct.encoder1.mu.layer_dim = [h_zy_dim, z_dim]\n",
    "    struct.encoder1.mu.activation = [None]\n",
    "    struct.encoder1.mu.learning_rate = [learning_rate, learning_rate]\n",
    "    struct.encoder1.mu.decay = [1, 1]      \n",
    "    struct.encoder1.sigma.layer_dim = [h_zy_dim, z_dim]\n",
    "    struct.encoder1.sigma.activation = [None]\n",
    "    struct.encoder1.sigma.learning_rate = [learning_rate, learning_rate]\n",
    "    struct.encoder1.sigma.decay = [1, 1]   \n",
    "    \n",
    "    struct.encoder2.share.layer_dim = [z_dim+y_dim, h_ay_dim]\n",
    "    struct.encoder2.share.activation = [ activation]\n",
    "    struct.encoder2.share.learning_rate = [learning_rate, learning_rate]\n",
    "    struct.encoder2.share.decay = [1, 1]                \n",
    "    struct.encoder2.mu.layer_dim = [h_ay_dim, a_dim]\n",
    "    struct.encoder2.mu.activation = [None]\n",
    "    struct.encoder2.mu.learning_rate = [learning_rate, learning_rate]\n",
    "    struct.encoder2.mu.decay = [1, 1]      \n",
    "    struct.encoder2.sigma.layer_dim = [h_ay_dim, a_dim]\n",
    "    struct.encoder2.sigma.activation = [None]\n",
    "    struct.encoder2.sigma.learning_rate = [learning_rate, learning_rate]\n",
    "    struct.encoder2.sigma.decay = [1, 1]\n",
    "    \n",
    "    '''\n",
    "    struct.encoder3.layer_dim = [z_dim, h_y_dim, y_dim]\n",
    "    struct.encoder3.activation = [activation, T.nnet.softmax]   \n",
    "    struct.encoder3.learning_rate = [learning_rate, learning_rate]\n",
    "    struct.encoder3.decay = [1, 1]     \n",
    "    '''\n",
    "    \n",
    "    struct.encoder3.layer_dim = [z_dim, y_dim]\n",
    "    struct.encoder3.activation = [ T.nnet.softmax]   \n",
    "    struct.encoder3.learning_rate = [learning_rate, learning_rate]\n",
    "    struct.encoder3.decay = [1, 1]     \n",
    "    \n",
    "    struct.decoder1.share.layer_dim = [z_dim+d_dim, h_zy_dim]\n",
    "    struct.decoder1.share.activation = [activation]\n",
    "    struct.decoder1.share.learning_rate = [learning_rate, learning_rate]\n",
    "    struct.decoder1.share.decay = [1, 1]                \n",
    "    struct.decoder1.mu.layer_dim = [h_zy_dim, x_dim]\n",
    "    struct.decoder1.mu.activation = [None]\n",
    "    struct.decoder1.mu.learning_rate = [learning_rate, learning_rate]\n",
    "    struct.decoder1.mu.decay = [1, 1]      \n",
    "    struct.decoder1.sigma.layer_dim = [h_zy_dim, x_dim]\n",
    "    struct.decoder1.sigma.activation = [None]\n",
    "    struct.decoder1.sigma.learning_rate = [learning_rate, learning_rate]\n",
    "    struct.decoder1.sigma.decay = [1, 1]      \n",
    "    \n",
    "    struct.decoder2.share.layer_dim = [a_dim+y_dim, h_ay_dim]\n",
    "    struct.decoder2.share.activation = [activation]\n",
    "    struct.decoder2.share.learning_rate = [learning_rate, learning_rate]\n",
    "    struct.decoder2.share.decay = [1, 1]                \n",
    "    struct.decoder2.mu.layer_dim = [h_ay_dim, z_dim]\n",
    "    struct.decoder2.mu.activation = [None]\n",
    "    struct.decoder2.mu.learning_rate = [learning_rate, learning_rate]\n",
    "    struct.decoder2.mu.decay = [1, 1]      \n",
    "    struct.decoder2.sigma.layer_dim = [h_ay_dim, z_dim]\n",
    "    struct.decoder2.sigma.activation = [None]\n",
    "    struct.decoder2.sigma.learning_rate = [learning_rate, learning_rate]\n",
    "    struct.decoder2.sigma.decay = [1, 1]       \n",
    "    \n",
    "    struct.DomainClassifier.layer_dim = [z_dim, d_dim]\n",
    "    struct.DomainClassifier.activation = [ T.nnet.softmax]   \n",
    "    struct.DomainClassifier.learning_rate = [0.01, 0.01]\n",
    "    struct.DomainClassifier.decay = [1, 1]      \n",
    "    \n",
    "    \n",
    "    coef = VANN.VANN_coef(\n",
    "        alpha = 1000,\n",
    "        beta = 100,        \n",
    "        L = 1,\n",
    "        optimize = 'Adam_update'  \n",
    "    )        \n",
    "    \n",
    "    description = 'AmazonReviews_mf%i_VANN_%s' % (max_feature, coef.optimize) \n",
    "    \n",
    "    \n",
    "    features_model, test_model, trained_param = VANN.VANN_training(\n",
    "        source_data = source_data,\n",
    "        target_data = target_data,\n",
    "        n_train_batches = 20,\n",
    "        n_epochs = 100,\n",
    "        k = 10,\n",
    "        struct = struct,\n",
    "        coef = coef,\n",
    "        description = description\n",
    "    )\n",
    "    \n",
    "    sample_n = 200\n",
    "    fp.features_plot(features_model, test_model, source_data, target_data, sample_n, description)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
